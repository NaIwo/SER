data:
  source-name: wav2vec_mean  # if you process data with a preprocessor, this name will be taken as the data output directory.
  path-extension: wav
  dataset:
    name: MELD
    batch-size: 32
    train-size: 1.0
    test-size: 1.0
    val-size: 1.0
    desired-sampling-rate: 16000
    prefetch: 2
    desired-length: null
    padding-value: 0.0
    shuffle-seed: null
    resample-training-set: False
model:
  wav2vec2:
    name: Wav2vecClassifier
    pretrained-model: facebook/wav2vec2-base-960h
    save-dir: ../../results/saved_models/meld/meld_mlp_clf
    aggregation: mean
    mode: training # {training, testing}
    train-epochs: 6
  gemaps-mfcc:
    classic:
      plot-dir: ../../results/plots
      model-labels:
        - SVM
        - RF
        - LR
        - MLP
        - DT
        - GBT
      svm:
        c: 100
      random-forest:
        split-criterion: entropy
        max-depth: 12
      logistic-regression:
        c: 50
        max-iter: 1000
      mlp:
        max-iter: 500
      gbt:
        subsample: 0.5
    mfcc:
      save-dir: ../../results/saved_models/ravdess/mfcc_cnn_clf
      batch-size: 32
      number-coefficients: 13
      number-windows: 499
      train-epochs: 50
      mode: training
    gmaps:
      ~




